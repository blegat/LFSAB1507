\section{Complementary Treatment}

\subsection{Estimation of the noise-to-signal power ratio (NSR)}
\label{subsec:NSREstimation}
Deconvolution by the method of Wiener needs the NSR of the additive noise in the image. The problem of computing the NSR is that we need the original image, which we usually don't have, otherwise deblurring would have no meaning anymore. That is why we try to estimate the SNR by the following reasoning. The pixels of a zone that represent a background (e.g. an area of a blue sky) should be approximatively constant. So the variance of this area would me mostly due to the noise. So we will estimate the power of noise by the variance of such an area. This is the main idea of our matlab function $nsrEstimation(f,psf)$, with $f$ the processed image. % ca sert à quoi psf? %cmt choisir intervention humaine ou pas? if true..?

This function proposes two ways to handle this. In the first one, the user must select an area that he considers as background. In the second way, the function selects automatically five regions: four in the corners and one in the center. It computes the variance for each region and it takes the zone with the least variance. The second method is probably less precise because the predefined regions might not represent parts of a background. But it has the advantage that it doesn't need a human intervention which means there is less work for the user and deblurring also goes faster. Indeed, it's not possible to ask the user to detect a region of background everytime you want to deblur an image when the goal is to have an algorithm near to real-time.

Once we have an estimation for the noise power, we compute the variance of the whole image to get the signal power and we divide the first value by the scond one, giving an estimation of the NSR.


\subsection{Blur metrics}

To compare different methods of deblurring, we need to be able to give the perceptual quality of an image. Suppose we have the original image $F$ and we want to estimate the quality of another image $\hat{F}$ that is a blurred version of $F$ or an approximation of $F$ after a deblurring operation. An easy way to do this is computing the Mean Square Error (MSE) between both images:
\begin{equation}
MSE=\frac{1}{MN} \sum\limits_{m=1}^{n=1}\left(F(m,n)-\hat{F}(m,n)\right)^2.
\end{equation}

The problem of this method is that it highly depends on the scale of intensity of the image. That's why we prefer the Peak Signal-to-Noise Ratio (PSNR) that avoid this problem:
\begin{equation}
PSNR = -10 log \frac{MSE}{S^2},
\end{equation}
where $S$ is the maximum value that a pixel can reach (255 for 8bits coding). Here the bigger the PSNR is, the better the quality of the image.

The problem of both methods is that we need the original image. That is only possible when we blur the images ourselves and we test our different deblurring methods. But in a real situation, we don't know $F$. The only image we have is the blurred image $G$ and the result of a deblurring method $\hat{F}$, so we can apply MSE and PSNR to those images. But we still only get an estimation of how close both images are, not of the blur intensity itself. Our next method determines the quality of an image objectively and without referential image. The technique that we found is a no-reference blur metric that is based on the analysis of the spread of the edges in an image. No-reference means that the metric is not relative to the original but is a absolute value associated to an image.

When an image is blurred, its high spatial frequency values in the spectrum are attenuated. Blur is perceptually apparent along edges so the technique is based on the smoothing effect of it on the edges. According to SOOOOOURCE (marziliano2002),it is sufficient to measure blur along vertical edgdes. Here is the algorithm:\\
First we detect the edges by a Sobel filter for example. Then we scan each row of the image. When we detect a pixel that corresponds to an edge, we look for the local maximum and minimum on that row. The distance (in pixels) between those extrema represents the local blur. Finally, we get the global blur measure for whole the image by averaging the local blur values over all edge locations.

The matlab function $bordSobel(I,meth,tresh,direction)$ implements this algorithm. The inputs are the processed image $I$, the method used to determine the edges ($1=Sobel, 2=Prewitt, 3=Canny$), a treshold for those methods that is fixed at $0.0215$ if it is not specified and finally the direction of the edges (vertical or horizontal).

%TODO résultats
%TODO changer nom de bordSobel car ca peut une autre meth que Sobel


\subsection{EdgeTaper}

One of the main characteristic of the frequency domain is its periodicity. It means that at the edges of the pictures \todo{To be continued after getting a nap} 

\subsection{RGB - grayscaled images : analysis and treatment}

As described in the mathematical model, gray-scaled images and color images differ in their mathematical structure. The easiest way for Matlab to manage the color space is adopt a RGB (Red-Green-Blue) representation such that the output for a certain point of the map is a 3-dimensional vector (one dimension per primitive color) instead of a scalar in the case of a gray-scaled image. The image is thus represented by a matrix of three dimensions and the final color is a additive synthesis of these three components.
 
In the case of our work, we have adapted the program so that it works for both types of images (RGB or gray-scaled one). It is also possible for a user to choose to convert the image to be processed in gray-scaled with the GUI (which operates the rgb2gray.m function). The advantage of converting an image to gray-scaled before the process is a saving time (one-dimensional processing instead of 3 for RGB). For example, the gain of time by converting the images from the surveillance camera can be quite important. Furthermore, according to intended use, it is not always necessary to have a final color image (ie the deblurring of a registration plate).